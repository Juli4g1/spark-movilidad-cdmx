# ğŸš‡ spark-movilidad-cdmx

AnÃ¡lisis de movilidad del metro en la Ciudad de MÃ©xico usando PySpark sobre la plataforma Databricks.

---

## ğŸ“˜ DescripciÃ³n general

Este proyecto realiza un anÃ¡lisis distribuido de datos reales de afluencia del metro en CDMX. Utiliza Apache Spark a travÃ©s del entorno Databricks para explorar patrones de movilidad, identificar lÃ­neas mÃ¡s congestionadas, horarios pico y otros aspectos clave del transporte pÃºblico.

**Fuente de datos**: [Portal de Datos Abiertos CDMX](https://datos.cdmx.gob.mx/dataset/?organization=secretaria-de-movilidad)

**Archivo utilizado**: `AfluenciaMetro.csv`  
**TamaÃ±o**: ~51 MB  
**Formato**: CSV, con columnas como `fecha`, `lÃ­nea`, `estaciÃ³n`, `tipo de pago`, `afluencia`.

---

## ğŸ““ Notebook: `Practica Spark PPC.ipynb`

Este notebook contiene el cÃ³digo desarrollado en PySpark y ejecutado en Databricks. Fue exportado en formato `.ipynb` para facilitar su visualizaciÃ³n en GitHub y otras plataformas compatibles con Jupyter Notebooks.

### ğŸ” Contenido:
- **Carga del dataset** desde CSV.
- **Transformaciones** con Spark DataFrames:
  - ConversiÃ³n de tipos de datos.
  - Filtrado por columnas especÃ­ficas.
  - Agregaciones (`groupBy`, `sum`).
  - Ordenamientos (`orderBy`) para encontrar valores mÃ¡ximos y mÃ­nimos.
- **VisualizaciÃ³n** con `matplotlib`:
  - GrÃ¡ficas de barras de afluencia por lÃ­nea, estaciÃ³n, tipo de pago y mes.

---

## ğŸ§  AnÃ¡lisis de resultados

El anÃ¡lisis permitiÃ³ identificar:

- Las **lÃ­neas con mayor afluencia** (LÃ­nea 2 y LÃ­nea 3).
- Las **estaciones mÃ¡s concurridas**, especialmente en zonas de correspondencia o conectoras como Pantitlan y Constitucion de 1917.
- El **tipo de pago predominante** en distintas lÃ­neas en su mayoria es prepago (uso de tarjeta).
- La **distribuciÃ³n mensual** del flujo de pasajeros a lo largo del aÃ±o.

---

## ğŸ§µ Uso de IA (documentaciÃ³n requerida)

Se consultÃ³ IA (ChatGPT) para resolver dudas  durante el desarrollo en Databricks. Estas consultas incluyeron:

- âœ” CorrecciÃ³n de sintaxis invÃ¡lida en comentarios (`//` reemplazado por `#`).
- âœ” Ayuda para corregir sintaxis en funciones como `groupBy().agg()` y `orderBy()` en Spark DataFrames.
- âœ” OrientaciÃ³n para crear grÃ¡ficas usando `matplotlib.pyplot.bar()` s.


---


ğŸ—‚ Archivo Databricks (.dbc)
Este repositorio incluye un archivo .dbc que contiene el notebook original exportado desde la plataforma Databricks.

Nombre del archivo: Practica Spark PPC.dbc

Uso: Este archivo permite reimportar el notebook completo dentro de otro entorno Databricks, manteniendo la estructura, celdas y metadatos.

LimitaciÃ³n: No es legible directamente desde GitHub ni compatible con editores como Jupyter o Colab.

Instrucciones: Para abrirlo, ve a tu espacio de trabajo en Databricks, selecciona Import > File y carga el archivo .dbc.

ğŸ“ Este archivo se incluye como respaldo del trabajo completo realizado en Databricks, ideal para reutilizaciÃ³n o migraciÃ³n del notebook.
